import { __awaiter, __asyncGenerator, __asyncValues, __await } from 'tslib';
import { SpanKind, trace, context } from '@opentelemetry/api';
import { InstrumentationBase, InstrumentationNodeModuleDefinition, safeExecuteInTheMiddle } from '@opentelemetry/instrumentation';
import { SpanAttributes, CONTEXT_KEY_ALLOW_TRACE_CONTENT } from '@traceloop/ai-semantic-conventions';
import { encodingForModel } from 'js-tiktoken';

var version = "0.22.0";

/**
 * Calculate completion tokens for image generation based on OpenAI's actual token costs
 *
 * Token costs based on OpenAI documentation:
 * For gpt-image-1:     Square (1024×1024)    Portrait (1024×1536)    Landscape (1536×1024)
 * Low                  272 tokens            408 tokens              400 tokens
 * Medium               1056 tokens           1584 tokens             1568 tokens
 * High                 4160 tokens           6240 tokens             6208 tokens
 *
 * For DALL-E 3:
 * Standard             1056 tokens           1584 tokens             1568 tokens
 * HD                   4160 tokens           6240 tokens             6208 tokens
 */
function calculateImageGenerationTokens(params, imageCount) {
    var _a;
    const size = (params === null || params === void 0 ? void 0 : params.size) || "1024x1024";
    const model = (params === null || params === void 0 ? void 0 : params.model) || "dall-e-2";
    const quality = (params === null || params === void 0 ? void 0 : params.quality) || "standard";
    // Token costs for different models and sizes
    let tokensPerImage;
    if (model === "dall-e-2") {
        // DALL-E 2 has fixed costs regardless of quality
        const dalle2Costs = {
            "256x256": 68,
            "512x512": 272,
            "1024x1024": 1056,
        };
        tokensPerImage = dalle2Costs[size] || 1056;
    }
    else if (model === "dall-e-3") {
        // DALL-E 3 costs depend on quality and size
        const dalle3Costs = {
            standard: {
                "1024x1024": 1056,
                "1024x1792": 1584,
                "1792x1024": 1568,
            },
            hd: {
                "1024x1024": 4160,
                "1024x1792": 6240,
                "1792x1024": 6208,
            },
        };
        tokensPerImage =
            ((_a = dalle3Costs[quality]) === null || _a === void 0 ? void 0 : _a[size]) || dalle3Costs["standard"]["1024x1024"];
    }
    else {
        // Default fallback for unknown models
        tokensPerImage = 1056;
    }
    return tokensPerImage * imageCount;
}
function processImageInRequest(image_1, traceId_1, spanId_1, uploadCallback_1) {
    return __awaiter(this, arguments, void 0, function* (image, traceId, spanId, uploadCallback, index = 0) {
        try {
            let base64Data;
            let filename;
            if (typeof image === "string") {
                // Could be a file path, base64 string, or URL
                if (image.startsWith("data:image/")) {
                    const commaIndex = image.indexOf(",");
                    base64Data = image.substring(commaIndex + 1);
                    filename = `input_image_${index}.png`;
                }
                else if (image.startsWith("http")) {
                    return null;
                }
                else {
                    base64Data = image;
                    filename = `input_image_${index}.png`;
                }
            }
            else if (image && typeof image === "object") {
                // Handle Node.js Buffer objects and ReadStream
                if (Buffer.isBuffer(image)) {
                    base64Data = image.toString("base64");
                    filename = `input_image_${index}.png`;
                }
                else if (image.read && typeof image.read === "function") {
                    const chunks = [];
                    return new Promise((resolve) => {
                        image.on("data", (chunk) => chunks.push(chunk));
                        image.on("end", () => __awaiter(this, void 0, void 0, function* () {
                            try {
                                const buffer = Buffer.concat(chunks);
                                const base64Data = buffer.toString("base64");
                                const filename = image.path || `input_image_${index}.png`;
                                const url = yield uploadCallback(traceId, spanId, filename, base64Data);
                                resolve(url);
                            }
                            catch (error) {
                                console.error("Error processing stream image:", error);
                                resolve(null);
                            }
                        }));
                        image.on("error", (error) => {
                            console.error("Error reading image stream:", error);
                            resolve(null);
                        });
                    });
                }
                else {
                    return null;
                }
            }
            else {
                return null;
            }
            const url = yield uploadCallback(traceId, spanId, filename, base64Data);
            return url;
        }
        catch (error) {
            console.error("Error processing image in request:", error);
            return null;
        }
    });
}
function setImageGenerationRequestAttributes(span, params) {
    const attributes = {};
    if (params.model) {
        attributes[SpanAttributes.LLM_REQUEST_MODEL] = params.model;
    }
    if (params.size) {
        attributes["gen_ai.request.image.size"] = params.size;
    }
    if (params.quality) {
        attributes["gen_ai.request.image.quality"] = params.quality;
    }
    if (params.style) {
        attributes["gen_ai.request.image.style"] = params.style;
    }
    if (params.n) {
        attributes["gen_ai.request.image.count"] = params.n;
    }
    if (params.prompt) {
        attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] = params.prompt;
        attributes[`${SpanAttributes.LLM_PROMPTS}.0.role`] = "user";
    }
    Object.entries(attributes).forEach(([key, value]) => {
        if (value !== undefined) {
            span.setAttribute(key, value);
        }
    });
}
function setImageEditRequestAttributes(span, params, uploadCallback) {
    return __awaiter(this, void 0, void 0, function* () {
        const attributes = {};
        if (params.model) {
            attributes[SpanAttributes.LLM_REQUEST_MODEL] = params.model;
        }
        if (params.size) {
            attributes["gen_ai.request.image.size"] = params.size;
        }
        if (params.n) {
            attributes["gen_ai.request.image.count"] = params.n;
        }
        if (params.prompt) {
            attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] = params.prompt;
            attributes[`${SpanAttributes.LLM_PROMPTS}.0.role`] = "user";
        }
        // Process input image if upload callback is available
        if (params.image &&
            uploadCallback &&
            span.spanContext().traceId &&
            span.spanContext().spanId) {
            const traceId = span.spanContext().traceId;
            const spanId = span.spanContext().spanId;
            const imageUrl = yield processImageInRequest(params.image, traceId, spanId, uploadCallback, 0);
            if (imageUrl) {
                attributes[`${SpanAttributes.LLM_PROMPTS}.1.content`] = JSON.stringify([
                    { type: "image_url", image_url: { url: imageUrl } },
                ]);
                attributes[`${SpanAttributes.LLM_PROMPTS}.1.role`] = "user";
            }
        }
        Object.entries(attributes).forEach(([key, value]) => {
            if (value !== undefined) {
                span.setAttribute(key, value);
            }
        });
    });
}
function setImageVariationRequestAttributes(span, params, uploadCallback) {
    return __awaiter(this, void 0, void 0, function* () {
        const attributes = {};
        if (params.model) {
            attributes[SpanAttributes.LLM_REQUEST_MODEL] = params.model;
        }
        if (params.size) {
            attributes["gen_ai.request.image.size"] = params.size;
        }
        if (params.n) {
            attributes["gen_ai.request.image.count"] = params.n;
        }
        // Process input image if upload callback is available
        if (params.image &&
            uploadCallback &&
            span.spanContext().traceId &&
            span.spanContext().spanId) {
            const traceId = span.spanContext().traceId;
            const spanId = span.spanContext().spanId;
            const imageUrl = yield processImageInRequest(params.image, traceId, spanId, uploadCallback, 0);
            if (imageUrl) {
                attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] = JSON.stringify([
                    { type: "image_url", image_url: { url: imageUrl } },
                ]);
                attributes[`${SpanAttributes.LLM_PROMPTS}.0.role`] = "user";
            }
        }
        Object.entries(attributes).forEach(([key, value]) => {
            if (value !== undefined) {
                span.setAttribute(key, value);
            }
        });
    });
}
function setImageGenerationResponseAttributes(span, response, uploadCallback, instrumentationConfig, params) {
    return __awaiter(this, void 0, void 0, function* () {
        const attributes = {};
        if (response.data && response.data.length > 0) {
            const completionTokens = calculateImageGenerationTokens(params, response.data.length);
            attributes[SpanAttributes.LLM_USAGE_COMPLETION_TOKENS] = completionTokens;
            // Calculate prompt tokens if enrichTokens is enabled
            if (instrumentationConfig === null || instrumentationConfig === void 0 ? void 0 : instrumentationConfig.enrichTokens) {
                try {
                    let estimatedPromptTokens = 0;
                    if (params === null || params === void 0 ? void 0 : params.prompt) {
                        estimatedPromptTokens += Math.ceil(params.prompt.length / 4);
                    }
                    if (params === null || params === void 0 ? void 0 : params.image) {
                        estimatedPromptTokens += 272;
                    }
                    if (estimatedPromptTokens > 0) {
                        attributes[SpanAttributes.LLM_USAGE_PROMPT_TOKENS] =
                            estimatedPromptTokens;
                    }
                    attributes[SpanAttributes.LLM_USAGE_TOTAL_TOKENS] =
                        estimatedPromptTokens + completionTokens;
                }
                catch (_a) {
                    attributes[SpanAttributes.LLM_USAGE_TOTAL_TOKENS] = completionTokens;
                }
            }
            else {
                attributes[SpanAttributes.LLM_USAGE_TOTAL_TOKENS] = completionTokens;
            }
        }
        if (response.data && response.data.length > 0) {
            const firstImage = response.data[0];
            if (firstImage.b64_json && uploadCallback) {
                try {
                    const traceId = span.spanContext().traceId;
                    const spanId = span.spanContext().spanId;
                    const imageUrl = yield uploadCallback(traceId, spanId, "generated_image.png", firstImage.b64_json);
                    attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.content`] =
                        JSON.stringify([{ type: "image_url", image_url: { url: imageUrl } }]);
                    attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.role`] = "assistant";
                }
                catch (error) {
                    console.error("Failed to upload generated image:", error);
                }
            }
            else if (firstImage.url && uploadCallback) {
                try {
                    const traceId = span.spanContext().traceId;
                    const spanId = span.spanContext().spanId;
                    const response = yield fetch(firstImage.url);
                    const arrayBuffer = yield response.arrayBuffer();
                    const buffer = Buffer.from(arrayBuffer);
                    const base64Data = buffer.toString("base64");
                    const uploadedUrl = yield uploadCallback(traceId, spanId, "generated_image.png", base64Data);
                    attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.content`] =
                        JSON.stringify([
                            { type: "image_url", image_url: { url: uploadedUrl } },
                        ]);
                    attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.role`] = "assistant";
                }
                catch (error) {
                    console.error("Failed to fetch and upload generated image:", error);
                    attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.content`] =
                        JSON.stringify([
                            { type: "image_url", image_url: { url: firstImage.url } },
                        ]);
                    attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.role`] = "assistant";
                }
            }
            else if (firstImage.url) {
                attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.content`] =
                    JSON.stringify([
                        { type: "image_url", image_url: { url: firstImage.url } },
                    ]);
                attributes[`${SpanAttributes.LLM_COMPLETIONS}.0.role`] = "assistant";
            }
            if (firstImage.revised_prompt) {
                attributes["gen_ai.response.revised_prompt"] = firstImage.revised_prompt;
            }
        }
        Object.entries(attributes).forEach(([key, value]) => {
            if (value !== undefined) {
                span.setAttribute(key, value);
            }
        });
    });
}
function wrapImageGeneration(tracer, uploadCallback, instrumentationConfig) {
    return function (original) {
        return function (...args) {
            const params = args[0];
            const span = tracer.startSpan("openai.images.generate", {
                kind: SpanKind.CLIENT,
                attributes: {
                    [SpanAttributes.LLM_SYSTEM]: "OpenAI",
                    "gen_ai.request.type": "image_generation",
                },
            });
            const response = original.apply(this, args);
            if (response && typeof response.then === "function") {
                return response
                    .then((result) => __awaiter(this, void 0, void 0, function* () {
                    try {
                        setImageGenerationRequestAttributes(span, params);
                        yield setImageGenerationResponseAttributes(span, result, uploadCallback, instrumentationConfig, params);
                        return result;
                    }
                    catch (error) {
                        span.recordException(error);
                        throw error;
                    }
                    finally {
                        span.end();
                    }
                }))
                    .catch((error) => {
                    span.recordException(error);
                    span.end();
                    throw error;
                });
            }
            else {
                try {
                    setImageGenerationRequestAttributes(span, params);
                    return response;
                }
                catch (error) {
                    span.recordException(error);
                    throw error;
                }
                finally {
                    span.end();
                }
            }
        };
    };
}
function wrapImageEdit(tracer, uploadCallback, instrumentationConfig) {
    return function (original) {
        return function (...args) {
            const params = args[0];
            const span = tracer.startSpan("openai.images.edit", {
                kind: SpanKind.CLIENT,
                attributes: {
                    [SpanAttributes.LLM_SYSTEM]: "OpenAI",
                    "gen_ai.request.type": "image_edit",
                },
            });
            const setRequestAttributesPromise = setImageEditRequestAttributes(span, params, uploadCallback).catch((error) => {
                console.error("Error setting image edit request attributes:", error);
            });
            const response = original.apply(this, args);
            if (response && typeof response.then === "function") {
                return response
                    .then((result) => __awaiter(this, void 0, void 0, function* () {
                    try {
                        yield setRequestAttributesPromise;
                        yield setImageGenerationResponseAttributes(span, result, uploadCallback, instrumentationConfig, params);
                        return result;
                    }
                    catch (error) {
                        span.recordException(error);
                        throw error;
                    }
                    finally {
                        span.end();
                    }
                }))
                    .catch((error) => __awaiter(this, void 0, void 0, function* () {
                    yield setRequestAttributesPromise;
                    span.recordException(error);
                    span.end();
                    throw error;
                }));
            }
            else {
                try {
                    return response;
                }
                catch (error) {
                    span.recordException(error);
                    throw error;
                }
                finally {
                    span.end();
                }
            }
        };
    };
}
function wrapImageVariation(tracer, uploadCallback, instrumentationConfig) {
    return function (original) {
        return function (...args) {
            const params = args[0];
            const span = tracer.startSpan("openai.images.createVariation", {
                kind: SpanKind.CLIENT,
                attributes: {
                    [SpanAttributes.LLM_SYSTEM]: "OpenAI",
                    "gen_ai.request.type": "image_variation",
                },
            });
            const response = original.apply(this, args);
            if (response && typeof response.then === "function") {
                return response
                    .then((result) => __awaiter(this, void 0, void 0, function* () {
                    try {
                        yield setImageVariationRequestAttributes(span, params, uploadCallback);
                        yield setImageGenerationResponseAttributes(span, result, uploadCallback, instrumentationConfig, params);
                        return result;
                    }
                    catch (error) {
                        span.recordException(error);
                        throw error;
                    }
                    finally {
                        span.end();
                    }
                }))
                    .catch((error) => {
                    span.recordException(error);
                    span.end();
                    throw error;
                });
            }
            else {
                try {
                    return response;
                }
                catch (error) {
                    span.recordException(error);
                    throw error;
                }
                finally {
                    span.end();
                }
            }
        };
    };
}

class OpenAIInstrumentation extends InstrumentationBase {
    constructor(config = {}) {
        super("@traceloop/instrumentation-openai", version, config);
        this._encodingCache = new Map();
    }
    setConfig(config = {}) {
        super.setConfig(config);
    }
    manuallyInstrument(module) {
        this._diag.debug(`Manually instrumenting openai`);
        const openaiModule = module;
        this._wrap(openaiModule.Chat.Completions.prototype, "create", this.patchOpenAI("chat"));
        this._wrap(openaiModule.Completions.prototype, "create", this.patchOpenAI("completion"));
        if (openaiModule.Images) {
            this._wrap(openaiModule.Images.prototype, "generate", wrapImageGeneration(this.tracer, this._config.uploadBase64Image, this._config));
            this._wrap(openaiModule.Images.prototype, "edit", wrapImageEdit(this.tracer, this._config.uploadBase64Image, this._config));
            this._wrap(openaiModule.Images.prototype, "createVariation", wrapImageVariation(this.tracer, this._config.uploadBase64Image, this._config));
        }
    }
    init() {
        const module = new InstrumentationNodeModuleDefinition("openai", [">=4 <6"], this.patch.bind(this), this.unpatch.bind(this));
        return module;
    }
    patch(moduleExports, moduleVersion) {
        this._diag.debug(`Patching openai@${moduleVersion}`);
        // Old version of OpenAI API (v3.1.0)
        if (moduleExports.OpenAIApi) {
            this._wrap(moduleExports.OpenAIApi.prototype, "createChatCompletion", this.patchOpenAI("chat", "v3"));
            this._wrap(moduleExports.OpenAIApi.prototype, "createCompletion", this.patchOpenAI("completion", "v3"));
        }
        else {
            this._wrap(moduleExports.OpenAI.Chat.Completions.prototype, "create", this.patchOpenAI("chat"));
            this._wrap(moduleExports.OpenAI.Completions.prototype, "create", this.patchOpenAI("completion"));
            if (moduleExports.OpenAI.Images) {
                this._wrap(moduleExports.OpenAI.Images.prototype, "generate", wrapImageGeneration(this.tracer, this._config.uploadBase64Image, this._config));
                this._wrap(moduleExports.OpenAI.Images.prototype, "edit", wrapImageEdit(this.tracer, this._config.uploadBase64Image, this._config));
                this._wrap(moduleExports.OpenAI.Images.prototype, "createVariation", wrapImageVariation(this.tracer, this._config.uploadBase64Image, this._config));
            }
        }
        return moduleExports;
    }
    unpatch(moduleExports, moduleVersion) {
        this._diag.debug(`Unpatching openai@${moduleVersion}`);
        // Old version of OpenAI API (v3.1.0)
        if (moduleExports.OpenAIApi) {
            this._unwrap(moduleExports.OpenAIApi.prototype, "createChatCompletion");
            this._unwrap(moduleExports.OpenAIApi.prototype, "createCompletion");
        }
        else {
            this._unwrap(moduleExports.OpenAI.Chat.Completions.prototype, "create");
            this._unwrap(moduleExports.OpenAI.Completions.prototype, "create");
            if (moduleExports.OpenAI.Images) {
                this._unwrap(moduleExports.OpenAI.Images.prototype, "generate");
                this._unwrap(moduleExports.OpenAI.Images.prototype, "edit");
                this._unwrap(moduleExports.OpenAI.Images.prototype, "createVariation");
            }
        }
    }
    patchOpenAI(type, version = "v4") {
        // eslint-disable-next-line @typescript-eslint/no-this-alias
        const plugin = this;
        // eslint-disable-next-line
        return (original) => {
            return function method(...args) {
                const span = type === "chat"
                    ? plugin.startSpan({
                        type,
                        params: args[0],
                        client: this,
                    })
                    : plugin.startSpan({
                        type,
                        params: args[0],
                        client: this,
                    });
                const execContext = trace.setSpan(context.active(), span);
                const execPromise = safeExecuteInTheMiddle(() => {
                    return context.with(execContext, () => {
                        var _a;
                        if ((_a = args === null || args === void 0 ? void 0 : args[0]) === null || _a === void 0 ? void 0 : _a.extraAttributes) {
                            delete args[0].extraAttributes;
                        }
                        return original.apply(this, args);
                    });
                }, (e) => {
                    if (e) {
                        plugin._diag.error("OpenAI instrumentation: error", e);
                    }
                });
                if (args[0].stream) {
                    return context.bind(execContext, plugin._streamingWrapPromise({
                        span,
                        type,
                        params: args[0],
                        promise: execPromise,
                    }));
                }
                const wrappedPromise = plugin._wrapPromise(type, version, span, execPromise);
                return context.bind(execContext, wrappedPromise);
            };
        };
    }
    startSpan({ type, params, client, }) {
        var _a, _b, _c, _d;
        const { provider } = this._detectVendorFromURL(client);
        const attributes = {
            [SpanAttributes.LLM_SYSTEM]: provider,
            [SpanAttributes.LLM_REQUEST_TYPE]: type,
        };
        try {
            attributes[SpanAttributes.LLM_REQUEST_MODEL] = params.model;
            if (params.max_tokens) {
                attributes[SpanAttributes.LLM_REQUEST_MAX_TOKENS] = params.max_tokens;
            }
            if (params.temperature) {
                attributes[SpanAttributes.LLM_REQUEST_TEMPERATURE] = params.temperature;
            }
            if (params.top_p) {
                attributes[SpanAttributes.LLM_REQUEST_TOP_P] = params.top_p;
            }
            if (params.frequency_penalty) {
                attributes[SpanAttributes.LLM_FREQUENCY_PENALTY] =
                    params.frequency_penalty;
            }
            if (params.presence_penalty) {
                attributes[SpanAttributes.LLM_PRESENCE_PENALTY] =
                    params.presence_penalty;
            }
            if (params.extraAttributes !== undefined &&
                typeof params.extraAttributes === "object") {
                Object.keys(params.extraAttributes).forEach((key) => {
                    // eslint-disable-next-line @typescript-eslint/no-non-null-assertion
                    attributes[key] = params.extraAttributes[key];
                });
            }
            if (this._shouldSendPrompts()) {
                if (type === "chat") {
                    params.messages.forEach((message, index) => {
                        attributes[`${SpanAttributes.LLM_PROMPTS}.${index}.role`] =
                            message.role;
                        if (typeof message.content === "string") {
                            attributes[`${SpanAttributes.LLM_PROMPTS}.${index}.content`] =
                                message.content || "";
                        }
                        else {
                            attributes[`${SpanAttributes.LLM_PROMPTS}.${index}.content`] =
                                JSON.stringify(message.content);
                        }
                    });
                    (_a = params.functions) === null || _a === void 0 ? void 0 : _a.forEach((func, index) => {
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.name`] = func.name;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.description`] = func.description;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.arguments`] = JSON.stringify(func.parameters);
                    });
                    (_b = params.tools) === null || _b === void 0 ? void 0 : _b.forEach((tool, index) => {
                        if (tool.type !== "function" ||
                            !("function" in tool) ||
                            !tool.function) {
                            return;
                        }
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.name`] = tool.function.name;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.description`] = tool.function.description;
                        attributes[`${SpanAttributes.LLM_REQUEST_FUNCTIONS}.${index}.arguments`] = JSON.stringify(tool.function.parameters);
                    });
                }
                else {
                    attributes[`${SpanAttributes.LLM_PROMPTS}.0.role`] = "user";
                    if (typeof params.prompt === "string") {
                        attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] =
                            params.prompt;
                    }
                    else {
                        attributes[`${SpanAttributes.LLM_PROMPTS}.0.content`] =
                            JSON.stringify(params.prompt);
                    }
                }
            }
        }
        catch (e) {
            this._diag.debug(e);
            (_d = (_c = this._config).exceptionLogger) === null || _d === void 0 ? void 0 : _d.call(_c, e);
        }
        return this.tracer.startSpan(`openai.${type}`, {
            kind: SpanKind.CLIENT,
            attributes,
        });
    }
    _streamingWrapPromise(_a) {
        return __asyncGenerator(this, arguments, function* _streamingWrapPromise_1({ span, type, params, promise, }) {
            var _b, e_1, _c, _d, _e, e_2, _f, _g;
            var _h, _j, _k, _l, _m, _o, _p, _q, _r, _s, _t, _u, _v, _w, _x, _y, _z, _0, _1, _2, _3, _4, _5, _6, _7, _8;
            if (type === "chat") {
                const result = {
                    id: "0",
                    created: -1,
                    model: "",
                    choices: [
                        {
                            index: 0,
                            logprobs: null,
                            finish_reason: "stop",
                            message: {
                                role: "assistant",
                                content: "",
                                tool_calls: [],
                            },
                        },
                    ],
                    object: "chat.completion",
                };
                try {
                    for (var _9 = true, _10 = __asyncValues(yield __await(promise)), _11; _11 = yield __await(_10.next()), _b = _11.done, !_b; _9 = true) {
                        _d = _11.value;
                        _9 = false;
                        const chunk = _d;
                        yield yield __await(chunk);
                        result.id = chunk.id;
                        result.created = chunk.created;
                        result.model = chunk.model;
                        if ((_h = chunk.choices[0]) === null || _h === void 0 ? void 0 : _h.finish_reason) {
                            result.choices[0].finish_reason = chunk.choices[0].finish_reason;
                        }
                        if ((_j = chunk.choices[0]) === null || _j === void 0 ? void 0 : _j.logprobs) {
                            result.choices[0].logprobs = chunk.choices[0].logprobs;
                        }
                        if ((_k = chunk.choices[0]) === null || _k === void 0 ? void 0 : _k.delta.content) {
                            result.choices[0].message.content += chunk.choices[0].delta.content;
                        }
                        if (((_l = chunk.choices[0]) === null || _l === void 0 ? void 0 : _l.delta.function_call) &&
                            ((_m = chunk.choices[0]) === null || _m === void 0 ? void 0 : _m.delta.function_call.arguments) &&
                            ((_o = chunk.choices[0]) === null || _o === void 0 ? void 0 : _o.delta.function_call.name)) {
                            // I needed to re-build the object so that Typescript will understand that `name` and `argument` are not null.
                            result.choices[0].message.function_call = {
                                name: chunk.choices[0].delta.function_call.name,
                                arguments: chunk.choices[0].delta.function_call.arguments,
                            };
                        }
                        for (const toolCall of (_r = (_q = (_p = chunk.choices[0]) === null || _p === void 0 ? void 0 : _p.delta) === null || _q === void 0 ? void 0 : _q.tool_calls) !== null && _r !== void 0 ? _r : []) {
                            if (((_t = (_s = result.choices[0].message.tool_calls) === null || _s === void 0 ? void 0 : _s.length) !== null && _t !== void 0 ? _t : 0) <
                                toolCall.index + 1) {
                                (_u = result.choices[0].message.tool_calls) === null || _u === void 0 ? void 0 : _u.push({
                                    function: {
                                        name: "",
                                        arguments: "",
                                    },
                                    id: "",
                                    type: "function",
                                });
                            }
                            if (result.choices[0].message.tool_calls) {
                                if (toolCall.id) {
                                    result.choices[0].message.tool_calls[toolCall.index].id +=
                                        toolCall.id;
                                }
                                if (toolCall.type) {
                                    result.choices[0].message.tool_calls[toolCall.index].type =
                                        toolCall.type;
                                }
                                if ((_v = toolCall.function) === null || _v === void 0 ? void 0 : _v.name) {
                                    result.choices[0].message.tool_calls[toolCall.index].function.name += toolCall.function.name;
                                }
                                if ((_w = toolCall.function) === null || _w === void 0 ? void 0 : _w.arguments) {
                                    result.choices[0].message.tool_calls[toolCall.index].function.arguments += toolCall.function.arguments;
                                }
                            }
                        }
                    }
                }
                catch (e_1_1) { e_1 = { error: e_1_1 }; }
                finally {
                    try {
                        if (!_9 && !_b && (_c = _10.return)) yield __await(_c.call(_10));
                    }
                    finally { if (e_1) throw e_1.error; }
                }
                if ((_x = result.choices[0].logprobs) === null || _x === void 0 ? void 0 : _x.content) {
                    this._addLogProbsEvent(span, result.choices[0].logprobs);
                }
                if (this._config.enrichTokens) {
                    let promptTokens = 0;
                    for (const message of params.messages) {
                        promptTokens +=
                            (_y = this.tokenCountFromString(message.content, result.model)) !== null && _y !== void 0 ? _y : 0;
                    }
                    const completionTokens = this.tokenCountFromString((_z = result.choices[0].message.content) !== null && _z !== void 0 ? _z : "", result.model);
                    if (completionTokens) {
                        result.usage = {
                            prompt_tokens: promptTokens,
                            completion_tokens: completionTokens,
                            total_tokens: promptTokens + completionTokens,
                        };
                    }
                }
                this._endSpan({ span, type, result });
            }
            else {
                const result = {
                    id: "0",
                    created: -1,
                    model: "",
                    choices: [
                        {
                            index: 0,
                            logprobs: null,
                            finish_reason: "stop",
                            text: "",
                        },
                    ],
                    object: "text_completion",
                };
                try {
                    for (var _12 = true, _13 = __asyncValues(yield __await(promise)), _14; _14 = yield __await(_13.next()), _e = _14.done, !_e; _12 = true) {
                        _g = _14.value;
                        _12 = false;
                        const chunk = _g;
                        yield yield __await(chunk);
                        try {
                            result.id = chunk.id;
                            result.created = chunk.created;
                            result.model = chunk.model;
                            if ((_0 = chunk.choices[0]) === null || _0 === void 0 ? void 0 : _0.finish_reason) {
                                result.choices[0].finish_reason = chunk.choices[0].finish_reason;
                            }
                            if ((_1 = chunk.choices[0]) === null || _1 === void 0 ? void 0 : _1.logprobs) {
                                result.choices[0].logprobs = chunk.choices[0].logprobs;
                            }
                            if ((_2 = chunk.choices[0]) === null || _2 === void 0 ? void 0 : _2.text) {
                                result.choices[0].text += chunk.choices[0].text;
                            }
                        }
                        catch (e) {
                            this._diag.debug(e);
                            (_4 = (_3 = this._config).exceptionLogger) === null || _4 === void 0 ? void 0 : _4.call(_3, e);
                        }
                    }
                }
                catch (e_2_1) { e_2 = { error: e_2_1 }; }
                finally {
                    try {
                        if (!_12 && !_e && (_f = _13.return)) yield __await(_f.call(_13));
                    }
                    finally { if (e_2) throw e_2.error; }
                }
                try {
                    if (result.choices[0].logprobs) {
                        this._addLogProbsEvent(span, result.choices[0].logprobs);
                    }
                    if (this._config.enrichTokens) {
                        const promptTokens = (_5 = this.tokenCountFromString(params.prompt, result.model)) !== null && _5 !== void 0 ? _5 : 0;
                        const completionTokens = this.tokenCountFromString((_6 = result.choices[0].text) !== null && _6 !== void 0 ? _6 : "", result.model);
                        if (completionTokens) {
                            result.usage = {
                                prompt_tokens: promptTokens,
                                completion_tokens: completionTokens,
                                total_tokens: promptTokens + completionTokens,
                            };
                        }
                    }
                }
                catch (e) {
                    this._diag.debug(e);
                    (_8 = (_7 = this._config).exceptionLogger) === null || _8 === void 0 ? void 0 : _8.call(_7, e);
                }
                this._endSpan({ span, type, result });
            }
        });
    }
    _wrapPromise(type, version, span, promise) {
        return promise._thenUnwrap((result) => {
            if (version === "v3") {
                if (type === "chat") {
                    this._addLogProbsEvent(span, result.data.choices[0].logprobs);
                    this._endSpan({
                        type,
                        span,
                        result: result.data,
                    });
                }
                else {
                    this._addLogProbsEvent(span, result.data.choices[0].logprobs);
                    this._endSpan({
                        type,
                        span,
                        result: result.data,
                    });
                }
            }
            else {
                if (type === "chat") {
                    this._addLogProbsEvent(span, result.choices[0].logprobs);
                    this._endSpan({ type, span, result: result });
                }
                else {
                    this._addLogProbsEvent(span, result.choices[0].logprobs);
                    this._endSpan({ type, span, result: result });
                }
            }
            return result;
        });
    }
    _endSpan({ span, type, result, }) {
        var _a, _b, _c, _d, _e;
        try {
            span.setAttribute(SpanAttributes.LLM_RESPONSE_MODEL, result.model);
            if (result.usage) {
                span.setAttribute(SpanAttributes.LLM_USAGE_TOTAL_TOKENS, (_a = result.usage) === null || _a === void 0 ? void 0 : _a.total_tokens);
                span.setAttribute(SpanAttributes.LLM_USAGE_COMPLETION_TOKENS, (_b = result.usage) === null || _b === void 0 ? void 0 : _b.completion_tokens);
                span.setAttribute(SpanAttributes.LLM_USAGE_PROMPT_TOKENS, (_c = result.usage) === null || _c === void 0 ? void 0 : _c.prompt_tokens);
            }
            if (this._shouldSendPrompts()) {
                if (type === "chat") {
                    result.choices.forEach((choice, index) => {
                        var _a, _b, _c;
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.finish_reason`, choice.finish_reason);
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.role`, choice.message.role);
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.content`, (_a = choice.message.content) !== null && _a !== void 0 ? _a : "");
                        if (choice.message.function_call) {
                            span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.function_call.name`, choice.message.function_call.name);
                            span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.function_call.arguments`, choice.message.function_call.arguments);
                        }
                        for (const [toolIndex, toolCall,] of ((_c = (_b = choice === null || choice === void 0 ? void 0 : choice.message) === null || _b === void 0 ? void 0 : _b.tool_calls) === null || _c === void 0 ? void 0 : _c.entries()) || []) {
                            if (toolCall.type === "function" && "function" in toolCall) {
                                span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.tool_calls.${toolIndex}.name`, toolCall.function.name);
                                span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.tool_calls.${toolIndex}.arguments`, toolCall.function.arguments);
                            }
                        }
                    });
                }
                else {
                    result.choices.forEach((choice, index) => {
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.finish_reason`, choice.finish_reason);
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.role`, "assistant");
                        span.setAttribute(`${SpanAttributes.LLM_COMPLETIONS}.${index}.content`, choice.text);
                    });
                }
            }
        }
        catch (e) {
            this._diag.debug(e);
            (_e = (_d = this._config).exceptionLogger) === null || _e === void 0 ? void 0 : _e.call(_d, e);
        }
        span.end();
    }
    _shouldSendPrompts() {
        const contextShouldSendPrompts = context
            .active()
            .getValue(CONTEXT_KEY_ALLOW_TRACE_CONTENT);
        if (contextShouldSendPrompts !== undefined) {
            return contextShouldSendPrompts;
        }
        return this._config.traceContent !== undefined
            ? this._config.traceContent
            : true;
    }
    _addLogProbsEvent(span, logprobs) {
        var _a, _b;
        try {
            let result = [];
            if (!logprobs) {
                return;
            }
            const chatLogprobs = logprobs;
            const completionLogprobs = logprobs;
            if (chatLogprobs.content) {
                result = chatLogprobs.content.map((logprob) => {
                    return {
                        token: logprob.token,
                        logprob: logprob.logprob,
                    };
                });
            }
            else if ((completionLogprobs === null || completionLogprobs === void 0 ? void 0 : completionLogprobs.tokens) &&
                (completionLogprobs === null || completionLogprobs === void 0 ? void 0 : completionLogprobs.token_logprobs)) {
                completionLogprobs.tokens.forEach((token, index) => {
                    var _a;
                    const logprob = (_a = completionLogprobs.token_logprobs) === null || _a === void 0 ? void 0 : _a[index];
                    if (logprob) {
                        result.push({
                            token,
                            logprob,
                        });
                    }
                });
            }
            span.addEvent("logprobs", { logprobs: JSON.stringify(result) });
        }
        catch (e) {
            this._diag.debug(e);
            (_b = (_a = this._config).exceptionLogger) === null || _b === void 0 ? void 0 : _b.call(_a, e);
        }
    }
    tokenCountFromString(text, model) {
        var _a, _b;
        if (!text) {
            return 0;
        }
        let encoding = this._encodingCache.get(model);
        if (!encoding) {
            try {
                encoding = encodingForModel(model);
                this._encodingCache.set(model, encoding);
            }
            catch (e) {
                this._diag.debug(e);
                (_b = (_a = this._config).exceptionLogger) === null || _b === void 0 ? void 0 : _b.call(_a, e);
                return 0;
            }
        }
        return encoding.encode(text).length;
    }
    _detectVendorFromURL(client) {
        const modelVendor = "OpenAI";
        try {
            if (!(client === null || client === void 0 ? void 0 : client.baseURL)) {
                return { provider: "OpenAI", modelVendor };
            }
            const baseURL = client.baseURL.toLowerCase();
            if (baseURL.includes("azure") || baseURL.includes("openai.azure.com")) {
                return { provider: "Azure", modelVendor };
            }
            if (baseURL.includes("openai.com") ||
                baseURL.includes("api.openai.com")) {
                return { provider: "OpenAI", modelVendor };
            }
            if (baseURL.includes("amazonaws.com") || baseURL.includes("bedrock")) {
                return { provider: "AWS", modelVendor };
            }
            if (baseURL.includes("googleapis.com")) {
                return { provider: "Google", modelVendor };
            }
            if (baseURL.includes("openrouter")) {
                return { provider: "OpenRouter", modelVendor };
            }
            return { provider: "OpenAI", modelVendor };
        }
        catch (e) {
            this._diag.debug(`Failed to detect vendor from URL: ${e}`);
            return { provider: "OpenAI", modelVendor };
        }
    }
}

export { OpenAIInstrumentation };
//# sourceMappingURL=index.mjs.map
